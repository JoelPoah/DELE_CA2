{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in c:\\users\\p2112729\\.conda\\envs\\joel_gpu\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\p2112729\\.conda\\envs\\joel_gpu\\lib\\site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\p2112729\\.conda\\envs\\joel_gpu\\lib\\site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\p2112729\\.conda\\envs\\joel_gpu\\lib\\site-packages (from packaging->tensorflow_addons) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "# DL modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential, Model\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "! pip install tensorflow_addons\n",
    "from tensorflow_addons.layers import SpectralNormalization\n",
    "\n",
    "# relevent libraries \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## matplotlib stylings\n",
    "plt.rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "classes = {\n",
    "    0: 'Airplane',  1: 'Automobile',\n",
    "    2: 'Bird',      3: 'Cat',\n",
    "    4: 'Deer',      5: 'Dog',\n",
    "    6: 'Frog',      7: 'Horse',\n",
    "    8: 'Ship',      9: 'Truck' \n",
    "}\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test  = y_test.reshape(-1)\n",
    "\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000,)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000,)\n",
      "255\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print(x_train.max())\n",
    "print(x_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Pixel normalization\n",
    "> Dividing each of the pixels by 255 will normalize the pixels between -1 to 1\n",
    "We normalize the pixels so that it can increase the speed of the learning process\n",
    "Neural Network processes inputs uses small weights values. Large inputs can disrupt or slow down learning process.\n",
    "It is good that we normalize the pixels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 127.5 - 1\n",
    "x_test = x_test / 127.5 - 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIC OF GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (32,32,3) # dimensions of training images\n",
    "latent_dim = 128        # dimensions of latent vectors aka Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, rows=32, cols=32, channels=3, z = 10):\n",
    "        # Input shape\n",
    "        self.img_rows = rows\n",
    "        self.img_cols = cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z\n",
    "        optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',optimizer = optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        #Generator takes in noise to generate images\n",
    "\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((32, 32, 3)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    # function to create discriminator model\n",
    "    def build_discriminator(image_size):\n",
    "        weights_init = RandomNormal(mean=0, stddev=0.02)\n",
    "        discriminator = Sequential([\n",
    "            Input(shape=input_dim),\n",
    "\n",
    "            ## 2 by 2 Strides for downsampling\n",
    "            ## Leaky ReLU for Activation\n",
    "            SpectralNormalization(\n",
    "                Conv2D(64, kernel_size=4, strides=2, padding='same', kernel_initializer=weights_init)\n",
    "            ),\n",
    "            BatchNormalization(momentum=0.8),\n",
    "            LeakyReLU(0.2),\n",
    "           \n",
    "           # Conv 2\n",
    "           SpectralNormalization(\n",
    "               Conv2D(128, kernel_size=4, strides=2, padding='same', kernel_initializer=weights_init)\n",
    "           ),\n",
    "           BatchNormalization(momentum=0.8),\n",
    "           LeakyReLU(0.2),\n",
    "   \n",
    "           # Conv 3\n",
    "           SpectralNormalization(\n",
    "               Conv2D(256, kernel_size=4, strides=2, padding='same', kernel_initializer=weights_init)\n",
    "           ),\n",
    "           BatchNormalization(momentum=0.8),\n",
    "           LeakyReLU(0.2),\n",
    "           \n",
    "           # # Conv 4\n",
    "           SpectralNormalization(\n",
    "               Conv2D(512, kernel_size=4, strides=2, padding='same', kernel_initializer=weights_init)\n",
    "           ),\n",
    "           BatchNormalization(momentum=0.8),\n",
    "           LeakyReLU(0.2),\n",
    "   \n",
    "           GlobalMaxPooling2D(),\n",
    "           Dense(1, activation='sigmoid'),\n",
    "        ], name='discriminator_GAN')\n",
    "        return discriminator\n",
    "\n",
    "    def train(self, epochs, batch_size=256, save_interval=50):\n",
    "\n",
    "\n",
    "    \n",
    "            # Adversarial ground truths\n",
    "            valid = np.ones((batch_size, 1))\n",
    "            fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "            for epoch in range(epochs):\n",
    "    \n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "    \n",
    "                # Select a random half of images\n",
    "                idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "                imgs = x_train[idx]\n",
    "    \n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "    \n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "    \n",
    "                # Train the generator (wants discriminator to mistake images as real)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "    \n",
    "                # Plot the progress\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "    \n",
    "                # If at save interval => save generated image samples\n",
    "                if epoch % save_interval == 0:\n",
    "                    self.save_imgs(epoch)\n",
    "                \n",
    "                \n",
    "    def save_imgs(self, epoch):\n",
    "            r, c = 5, 5\n",
    "            noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "    \n",
    "            # Rescale images 0 - 1\n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    \n",
    "            fig, axs = plt.subplots(r, c)\n",
    "            cnt = 0\n",
    "            for i in range(r):\n",
    "                for j in range(c):\n",
    "                    axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                    axs[i,j].axis('off')\n",
    "                    cnt += 1\n",
    "            fig.savefig(\"dcgan_mnist_{:d}.png\".format(epoch))\n",
    "            plt.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_3\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [6272], output_shape = [32, 32, 3]\n\nCall arguments received by layer \"reshape_3\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 6272), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dcgan \u001b[38;5;241m=\u001b[39m \u001b[43mDCGAN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m dcgan\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, save_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[1;32mIn [16], line 15\u001b[0m, in \u001b[0;36mDCGAN.__init__\u001b[1;34m(self, rows, cols, channels, z)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer \u001b[38;5;241m=\u001b[39m optimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Build the generator\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#Generator takes in noise to generate images\u001b[39;00m\n\u001b[0;32m     19\u001b[0m z \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim,))\n",
      "Cell \u001b[1;32mIn [16], line 38\u001b[0m, in \u001b[0;36mDCGAN.build_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m128\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m7\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m7\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim))\n\u001b[1;32m---> 38\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39madd(UpSampling2D())\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m128\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\P2112729\\.conda\\envs\\joel_gpu\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\P2112729\\.conda\\envs\\joel_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\P2112729\\.conda\\envs\\joel_gpu\\lib\\site-packages\\keras\\layers\\reshaping\\reshape.py:118\u001b[0m, in \u001b[0;36mReshape._fix_unknown_dimension\u001b[1;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[0;32m    116\u001b[0m     output_shape[unknown] \u001b[39m=\u001b[39m original \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m known\n\u001b[0;32m    117\u001b[0m \u001b[39melif\u001b[39;00m original \u001b[39m!=\u001b[39m known:\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m output_shape\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_3\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [6272], output_shape = [32, 32, 3]\n\nCall arguments received by layer \"reshape_3\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 6272), dtype=float32)"
     ]
    }
   ],
   "source": [
    "dcgan = DCGAN(32,32,3)\n",
    "dcgan.train(epochs=200, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything below not mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Source: https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit#wrapping_up_an_end-to-end_gan_example\n",
    "class GAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name='generator_loss')\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name='discriminator_loss')\n",
    "        self.kl = tf.keras.metrics.KLDivergence()\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        ### TRAINING DISCRIMINATOR\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.zeros((batch_size, 1)), tf.ones((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        ### TRAINING GENERATOR\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            predictions = self.discriminator(generated_images)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor Loss\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.kl.update_state(y_true=real_images, y_pred=generated_images)\n",
    "        \n",
    "        return {\n",
    "            \"d_loss\": self.disc_loss_tracker.result(), \n",
    "            \"g_loss\": self.gen_loss_tracker.result(), \n",
    "            \"KL Divergence\": self.kl.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to monitor the Generator at every n epoch\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    # class GANMontor\n",
    "    # - num_img: number of images generated using matplotlib figure\n",
    "    # - latent_dim: dimensions of noise latent vector passed into the generator\n",
    "    # - patience: number of epochs to generate images\n",
    "    # - vmin: minumum scaling factor, a\n",
    "    # - vmax: maximum scaling factor, b\n",
    "    # NOTE: only compatible with the GAN class I've set up\n",
    "    def __init__(self, num_img=10, latent_dim=128, patience=10, vmin=0, vmax=1):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.patience = patience\n",
    "        self.vmin = vmin\n",
    "        self.vmax = vmax\n",
    "        self.constant_latent_vector = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "\n",
    "    # method to generate images and display them as matplotlib figure\n",
    "    def generate_plot(self):\n",
    "        # Generate Images\n",
    "        generated_images = self.model.generator(self.constant_latent_vector)\n",
    "\n",
    "        # Normalise Image from [vmin, vmax] to [0, 1]\n",
    "        generated_images -= self.vmin\n",
    "        generated_images /= (self.vmax - self.vmin)\n",
    "\n",
    "        # Generate Matplotlib Figure\n",
    "        row_size = np.ceil(self.num_img/5)\n",
    "        fig = plt.figure(figsize=(10, 2*row_size), tight_layout=True)\n",
    "        for i in range(self.num_img):\n",
    "            ax = fig.add_subplot(row_size, 5, i+1)\n",
    "            ax.imshow(generated_images[i])\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # method to save generator's weights\n",
    "    def save_weights(self, epoch=None):\n",
    "        try:\n",
    "            if epoch != None:\n",
    "                name='generator-epoch-{}.h5'.format(epoch)\n",
    "                print('Generator Checkpoint - {}'.format(name))\n",
    "                self.model.generator.save_weights(\n",
    "                    filepath=name,\n",
    "                    save_format='h5'\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    # generate a plot every n epochs\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch % self.patience == 0:\n",
    "            self.generate_plot()\n",
    "            self.save_weights(epoch)\n",
    "\n",
    "    # generate a plot after training\n",
    "    def on_train_end(self, epoch, logs=None):\n",
    "        self.generate_plot()\n",
    "        self.save_weights('Full Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Callback Functions\n",
    "callbacks = [\n",
    "    GANMonitor(num_img=15, latent_dim=128, patience=5, vmin=-1, vmax=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and Constants\n",
    "BATCH_SIZE  = 64\n",
    "LATENT_DIM  = 128\n",
    "AUTO        = tf.data.AUTOTUNE\n",
    "EPOCHS      = 100\n",
    "BUFFER_SIZE = 1024\n",
    "INPUT_DIM   = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reseting Graph variables\n",
    "tf.keras.backend.clear_session()\n",
    "K.clear_session()\n",
    "\n",
    "# Creating a GAN class\n",
    "gan = GAN(\n",
    "    discriminator=create_discriminator(image_size=INPUT_DIM), \n",
    "    generator=create_generator(latent_dim=LATENT_DIM), \n",
    "    latent_dim=latent_dim\n",
    ")\n",
    "# Compiling with Optimizer and Loss Function\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "# Preparing the Dataset with `tf.data`\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "dataset = dataset.shuffle(buffer_size=BUFFER_SIZE).batch(batch_size=BATCH_SIZE, num_parallel_calls=AUTO).prefetch(AUTO)\n",
    "\n",
    "# Starting the Train Process\n",
    "hist = gan.fit(dataset, epochs=EPOCHS, use_multiprocessing=True, workers=16, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story history object into dataframe\n",
    "hist_df = pd.DataFrame(hist.history)\n",
    "\n",
    "# plot the loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(hist_df['d_loss'], label='Discriminator Loss')\n",
    "plt.plot(hist_df['g_loss'], label='Generator Loss')\n",
    "plt.plot(hist_df['KL Divergence'], label='KL Divergence')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 1000 Synthetic Images\n",
    "random_noise = tf.random.normal(shape=(1000, latent_dim))\n",
    "synthetic_images = gan.generator.predict(random_noise)\n",
    "print(\"Latent Vector Dim: {}\\tGenerated Images Dim: {}\".format(random_noise.shape, synthetic_images.shape))\n",
    "\n",
    "# Scaling back to [0, 1]\n",
    "synthetic_images -= -1\n",
    "synthetic_images /= (1 - (-1))\n",
    "\n",
    "# Display 15 randomly sampled images\n",
    "fig = plt.figure(figsize=(10, 10), tight_layout=True)\n",
    "for i in range(25):\n",
    "    rand_idx = np.random.randint(0, len(synthetic_images))\n",
    "    ax = fig.add_subplot(5, 5, i+1)\n",
    "    ax.imshow(synthetic_images[rand_idx])\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics to see accuracy \n",
    "## FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries to calculate FID\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.image import resize\n",
    "from scipy.linalg import sqrtm\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_FID:\n",
    "    def __init__(self, batch_size, latent_dim, sample_size, buffer_size):\n",
    "        # setting Hyperparameters\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.LATENT_DIM = latent_dim\n",
    "        self.SAMPLE_SIZE = sample_size\n",
    "        self.BUFFER_SIZE = buffer_size\n",
    "\n",
    "        # setting Constants\n",
    "        self.INCEPTION_SHAPE = (299, 299, 3)\n",
    "        self.INCEPTION = InceptionV3(include_top=False, pooling='avg', input_shape=self.INCEPTION_SHAPE)\n",
    "        self.AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "    # method to set generator and training data\n",
    "    def fit(self, generator, train_data):\n",
    "        # setting generative model and original data used for training \n",
    "        self.GENERATOR = generator\n",
    "        self.train_data = train_data\n",
    "\n",
    "        # Preparing Real Images\n",
    "        trainloader = tf.data.Dataset.from_tensor_slices((self.train_data))\n",
    "        trainloader = (\n",
    "            trainloader\n",
    "            .shuffle(self.BUFFER_SIZE)\n",
    "            .map(self.__resize_and_preprocess, num_parallel_calls=self.AUTO)\n",
    "            .batch(self.BATCH_SIZE, num_parallel_calls=self.AUTO)\n",
    "            .prefetch(self.AUTO)\n",
    "        )\n",
    "        self.trainloader = trainloader\n",
    "\n",
    "        # Generate and prepare Synthetic Images (Fake)\n",
    "        noise = tf.random.normal([self.SAMPLE_SIZE, self.LATENT_DIM])\n",
    "        generated_images = self.GENERATOR(noise)\n",
    "        genloader = tf.data.Dataset.from_tensor_slices(generated_images)\n",
    "        genloader = (\n",
    "            genloader\n",
    "            .map(self.__resize_and_preprocess, num_parallel_calls=self.AUTO)\n",
    "            .batch(self.BATCH_SIZE, num_parallel_calls=self.AUTO)\n",
    "            .prefetch(self.AUTO)\n",
    "        )\n",
    "        self.genloader = genloader\n",
    "\n",
    "        # prepare embeddings\n",
    "        count = math.ceil(self.SAMPLE_SIZE/self.BATCH_SIZE)\n",
    "\n",
    "        ## compute embeddings for real images\n",
    "        print(\"Computing Real Image Embeddings\")\n",
    "        self.real_image_embeddings = self.__compute_embeddings(self.trainloader, count)\n",
    "\n",
    "        ## compute embeddings for generated images\n",
    "        print(\"Computing Generated Image Embeddings\")\n",
    "        self.generated_image_embeddings = self.__compute_embeddings(self.genloader, count)\n",
    "        assert self.real_image_embeddings.shape == self.generated_image_embeddings.shape, \"Embeddings are not of the same size\"\n",
    "        print(\"Computed Embeddings\\tReal Images Embedding Shape: {}\\tGenerated Images Embedding Shape: {}\".format(\n",
    "            self.real_image_embeddings.shape, \n",
    "            self.generated_image_embeddings.shape\n",
    "        ))\n",
    "    \n",
    "    # method to produce evaluation results\n",
    "    @tf.autograph.experimental.do_not_convert\n",
    "    def evaluate(self):\n",
    "        # calculate Frechet Inception Distance\n",
    "        fid = self.__calculate_fid(self.real_image_embeddings, self.generated_image_embeddings)\n",
    "        print('The computed FID score is:', fid)\n",
    "\n",
    "        return fid\n",
    "\n",
    "    # method to generate embeddings from inception model \n",
    "    def __compute_embeddings(self, dataloader, count):\n",
    "        image_embeddings = []\n",
    "        for _ in tqdm(range(count)):\n",
    "            images = next(iter(dataloader))\n",
    "            embeddings = self.INCEPTION.predict(images)\n",
    "            image_embeddings.extend(embeddings)\n",
    "        return np.array(image_embeddings)\n",
    "\n",
    "    ## STATIC METHODS: these methods knows nothing about the class\n",
    "    # static method to prepare the data before computing Inception Embeddings\n",
    "    @staticmethod\n",
    "    def __resize_and_preprocess(image):\n",
    "        # image *= 255.0 # original image are scaled to [0, 1], scaling back to [0, 255]\n",
    "        image -= -1\n",
    "        image /= (1 - (-1))\n",
    "        image *= 255.\n",
    "\n",
    "        # .preprocess_input() expects an image of scale [0, 255]\n",
    "        image = preprocess_input(image)\n",
    "        # inception model expects an image of shape (None, 299, 299, 3)\n",
    "        image = tf.image.resize(image, (299, 299), method='nearest')\n",
    "        return image\n",
    "\n",
    "    # static method to calculate frechet inception distance based on embeddings\n",
    "    @staticmethod \n",
    "    def __calculate_fid(real_embeddings, generated_embeddings):\n",
    "        # calculate mean and covariance statistics\n",
    "        mu1, sigma1 = real_embeddings.mean(axis=0), np.cov(real_embeddings, rowvar=False)\n",
    "        mu2, sigma2 = generated_embeddings.mean(axis=0), np.cov(generated_embeddings, rowvar=False)\n",
    "        # calculate sum squared difference between means\n",
    "        ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "        # calculate sqrt of product between cov\n",
    "        covmean = sqrtm(sigma1.dot(sigma2))\n",
    "        # check and correct imaginary numbers from sqrt\n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "        # calculate score\n",
    "        fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "        return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fid_class = GAN_FID(batch_size=512, latent_dim=128, sample_size=10000, buffer_size=1024)\n",
    "fid_class.fit(generator=gan.generator, train_data=x_train)\n",
    "fid_score = fid_class.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary information\n",
    "gan.generator.summary()\n",
    "\n",
    "# saving as .hdf format\n",
    "gan.generator.save(\"GAN_Generator.h5\")\n",
    "assert os.path.exists('GAN_Generator.h5'), \"GAN Generator does not exists\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('joel_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f87b2ba0695567226fd47786739bc0cb69a9f4337aa120baf744c6dd0597b59a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
